{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJOFuU2gJFGh"
      },
      "source": [
        "##[KUGGLE] NLP 자연어 처리 과제\n",
        "\n",
        "**실습 내용**\n",
        "* 자연어를 효과적으로 분석하기 위해 중요도가 떨어지는 문자 삭제해보기\n",
        "* 머신러닝으로 텍스트 데이터를 학습하기 위한 수치화 과정(bow) 실습\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrH240YHnx33"
      },
      "source": [
        "########## ⭐️ (과제) 문장을 넣어주세요 ############\n",
        "\n",
        "이 부분에 자연어 처리로 분석해보고 싶은 문장을 넣어 코드를 돌려주세요!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IjqH6edcPYK"
      },
      "source": [
        "##1. 숫자 및 특수 문자 삭제\n",
        "* 정규표현식 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dhi286o7u1gK"
      },
      "outputs": [],
      "source": [
        "# 데이터 프레임 생성을 위해 pandas 로드\n",
        "import pandas as pd\n",
        "\n",
        "# 특수 문자 및 숫자가 포함된 예시 텍스트 데이터\n",
        "texts = [ \"########## 하이 ############\"\n",
        "]\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "df = pd.DataFrame(texts, columns=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hUtVsYOkvYfK"
      },
      "outputs": [],
      "source": [
        "# 특수문자 제거\n",
        "df['text'] = df['text'].replace(r'[^\\w\\s]', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3Q2HCn64vaRR"
      },
      "outputs": [],
      "source": [
        "# 숫자 제거\n",
        "df['text'] = df['text'].replace(r'\\d+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ3EbE4SvbFB",
        "outputId": "3cd80d8d-6f58-408f-dbbb-3183c708e31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   text\n",
            "0   하이 \n"
          ]
        }
      ],
      "source": [
        "# 결과 출력\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGGyA1T0JZ4h"
      },
      "source": [
        "##2. 형태소 분석\n",
        "한국어 형태소 분석은 한국어 텍스트를 가장 작은 의미 단위인 형태소로 분해하는 과정입니다.\n",
        "\n",
        "형태소의 분해 과정\n",
        "* 분해: 한국어 문장을 어절 단위로 분해합니다.\n",
        "* 형태소 분석: 각 어절을 다시 형태소로 세분화 합니다. 이 과정에서 어근, 접미사, 접두사, 조사 등이 구분됩니다,\n",
        "* 품사 태깅: 분리된 형태소에 품사 정보를 부여합니다. 예를 들어, 명사, 동사, 형용사 등의 품사를 식별합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7bd1Kzmk7OX"
      },
      "source": [
        "##KoNLPy란\n",
        "* KoNLPy는 파이썬 기반 라이브러리로, 한국어 텍스트의 형태소 분석, 품사 태깅 등을 제공합니다.\n",
        "* KoNLPy에 여러 분석 엔진이 있는데 한국어 텍스트의 경우 대표적으로 okt가 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cBCw_RcKTxY"
      },
      "source": [
        "##KoNLPy 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-xiQsvnJB_r",
        "outputId": "7183b1ba-babd-41be-82c5-3db8f1d6bd98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.10/site-packages (24.3.1)\n",
            "Requirement already satisfied: JPype1 in /opt/anaconda3/lib/python3.10/site-packages (1.5.1)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.10/site-packages (from JPype1) (24.1)\n",
            "Requirement already satisfied: konlpy in /opt/anaconda3/lib/python3.10/site-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /opt/anaconda3/lib/python3.10/site-packages (from konlpy) (1.5.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from konlpy) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /opt/anaconda3/lib/python3.10/site-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy) (24.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install JPype1\n",
        "!pip install konlpy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaFEWN2XgUGQ",
        "outputId": "1a38f722-abab-4fd2-bd14-45afb8622ee2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('##########', 'Punctuation'),\n",
              " ('안녕하다', 'Adjective'),\n",
              " ('.', 'Punctuation'),\n",
              " ('############', 'Punctuation')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "# okt.tagset\n",
        "okt.pos(\"########## 안녕하세요. ############\",norm=True, stem=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlAFypzNMGsw"
      },
      "source": [
        "## 2-1 형태소 분석을 통한 불용어 삭제\n",
        "\n",
        "**불용어(Stopwords)**: 자연어 처리(NLP)에서 텍스트를 분석할 때 의미를 가지지 않거나 중요도가 낮아서 분석에서 제외되는 단어들을 말합니다.\n",
        "\n",
        "* ex) 한국어에서의 불용어: \"이\", \"그\", \"저\", \"것\", \"있다\", \"수\", \"들\", \"그리고\" 등\n",
        "\n",
        "* 조사, 접미사, 어미, 구두점 등이 주로 불용어에 해당합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGN7CoT6jSCm"
      },
      "source": [
        "##조사, 어미, 구두점 삭제하는 함수 만들어보기\n",
        "**KoNLPy 한국어 품사 태깅표:**https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit?gid=0#gid=0\n",
        "\n",
        "* 위 주소의 태깅표를 참고하여 실습해보시기 바랍니다.\n",
        "* 아래 작성된 코드는 형태소 분석기를 통해 지정 된 품사를 삭제하는 함수를 만든 것 입니다.\n",
        "* KoNLPy 품사 태깅표를 확인하여 여러 품사를 삭제하는 함수를 만들 수 있습니다.\n",
        "***okt는 품사 태깅표의 Twitter Korean Text를 참고하시면 됩니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CESIdMv7K2KZ"
      },
      "outputs": [],
      "source": [
        "# 형태소 분석기(Okt) 불러오기\n",
        "\n",
        "def okt_clean(text):\n",
        "    clean_text = []\n",
        "    okt_pos = okt.pos(text, stem=True)\n",
        "    for txt, pos in okt_pos:\n",
        "        if pos not in ['⭐️','⭐️','⭐️']: # KoNLPy 품사 태깅표 참고하여 조사 어미 구두점 삭제하는 함수 만들어보기\n",
        "          clean_text.append(txt)\n",
        "    return \" \".join(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kv0r0_f_QqiH",
        "outputId": "0d783c4e-fead-4519-e3b5-de8a5b809ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'자연어 처리 는 인공 지능 의 하다 분야 이다 .'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 실제 텍스트에 함수 적용해보기\n",
        "okt_clean(text=\"자연어 처리는 인공지능의 한 분야입니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6lPu2RZRkek"
      },
      "source": [
        "##3. 단어 가방(bow: bag of words)\n",
        "\n",
        "* 자연어 처리에서 텍스트 데이터를 행렬화하여 분석하기 위한 방법입니다.\n",
        "* 텍스트를 입력하게 되면 텍스트의 모든 단어들을 열로 사용하고 각 문서에서 단어가 얼마나 등장하는지를 행렬로 나타냅니다.\n",
        "* 단어의 순서나 문법적 구조는 무시하고 단순히 각 단어의 빈도수에 초점을 맞춥니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sqf9awFokiA"
      },
      "source": [
        "##라이브러리 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RpCo_sxRRj4-"
      },
      "outputs": [],
      "source": [
        "# 데이터 분석을 위한 pandas, 수치계산을 위한 numpy, 시각화를 위한 seaborn, matplotlib, koreanize_matplotlib 을 로드합니다.\n",
        "# sklearn.feature_extraction.text의 CountVectorizer 를 통해 BOW 를 생성\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVfXNs7aUl1V"
      },
      "source": [
        "## 3-1 CountVectorizer\n",
        "* CountVectorizer는 사이킷런에서 제공하는bag of words를 만들 수 있는 방법입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YuyPCY4KUled"
      },
      "outputs": [],
      "source": [
        "corpus = [\"코로나 거리두기와 코로나 상생지원금 문의입니다.\",\n",
        "          \"지하철 운행시간과 지하철 요금 문의입니다.\",\n",
        "          \"지하철 승강장 문의입니다.\",\n",
        "          \"코로나 선별진료소 문의입니다.\",\n",
        "          \"버스 운행시간 문의입니다.\",\n",
        "          \"버스 터미널 위치 안내입니다.\",\n",
        "          \"코로나 거리두기 안내입니다.\",\n",
        "          \"택시 승강장 문의입니다.\"\n",
        "         ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "zFZIPxEoWVpq",
        "outputId": "874a836e-abe2-46ca-ca5f-a236c9aad00a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>거리두기</th>\n",
              "      <th>거리두기와</th>\n",
              "      <th>문의입니다</th>\n",
              "      <th>버스</th>\n",
              "      <th>상생지원금</th>\n",
              "      <th>선별진료소</th>\n",
              "      <th>승강장</th>\n",
              "      <th>안내입니다</th>\n",
              "      <th>요금</th>\n",
              "      <th>운행시간</th>\n",
              "      <th>운행시간과</th>\n",
              "      <th>위치</th>\n",
              "      <th>지하철</th>\n",
              "      <th>코로나</th>\n",
              "      <th>택시</th>\n",
              "      <th>터미널</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   거리두기  거리두기와  문의입니다  버스  상생지원금  선별진료소  승강장  안내입니다  요금  운행시간  운행시간과  위치  지하철  \\\n",
              "0     0      1      1   0      1      0    0      0   0     0      0   0    0   \n",
              "1     0      0      1   0      0      0    0      0   1     0      1   0    2   \n",
              "2     0      0      1   0      0      0    1      0   0     0      0   0    1   \n",
              "3     0      0      1   0      0      1    0      0   0     0      0   0    0   \n",
              "4     0      0      1   1      0      0    0      0   0     1      0   0    0   \n",
              "5     0      0      0   1      0      0    0      1   0     0      0   1    0   \n",
              "6     1      0      0   0      0      0    0      1   0     0      0   0    0   \n",
              "7     0      0      1   0      0      0    1      0   0     0      0   0    0   \n",
              "\n",
              "   코로나  택시  터미널  \n",
              "0    2   0    0  \n",
              "1    0   0    0  \n",
              "2    0   0    0  \n",
              "3    1   0    0  \n",
              "4    0   0    0  \n",
              "5    0   0    1  \n",
              "6    1   0    0  \n",
              "7    0   1    0  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# CountVectorizer 인스턴스를 만듭니다.\n",
        "cvect = CountVectorizer()\n",
        "\n",
        "# 텍스트 데이터를 학습(fit)하고, 이를 BOW 형태로 변환(transform)합니다.\n",
        "X = cvect.fit_transform(corpus)\n",
        "\n",
        "# 이제 문장들이 숫자로 변환된 결과를 보기 좋게 표 형태로 만듭니다.\n",
        "#    - X.toarray()는 각 문장을 숫자로 변환한 결과를 보기 좋게 바꿔줍니다.\n",
        "#    - columns=cvect.get_feature_names_out()는 각 열(컬럼)에 해당하는 단어의 이름을 표에 추가해줍니다.\n",
        "pd.DataFrame(X.toarray(), columns=cvect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P08aEdlTgzP4"
      },
      "source": [
        "##CountVectorizer 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9lhkubB2gyV4"
      },
      "outputs": [],
      "source": [
        "corpus = [\"안녕하세요.반갑습니다.\"\n",
        "         ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TPdTvFofg6Wq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>반갑습니다</th>\n",
              "      <th>안녕하세요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   반갑습니다  안녕하세요\n",
              "0      1      1"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sklearn.feature_extraction.text의 CountVectorizer 를 통해 BOW 를 생성\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "cvect = CountVectorizer()\n",
        "X = cvect.fit_transform(corpus)\n",
        "pd.DataFrame(X.toarray(), columns=cvect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvMDzYO-Xv6s"
      },
      "source": [
        "## 3-2 N-grams\n",
        "* bow에서 토큰을 몇 개 사용할 것인지를 구분합니다. 지정한 n개의 숫자 만큼의 토큰을 묶어서 사용합니다.\n",
        "* 예를 들어 (1,1)이라면 1개의 토큰을 (2,3)이라면 2~3개의 토큰을 사용합니다.\n",
        "\n",
        "* 토큰: 자연어 처리에서 텍스트를 분석하기 위해 가장 작은 단위로 나눈 것 입니다.\n",
        "\n",
        "* 토큰을 (1,2) 설정하게 되면 기존의 하나의 단어로 행렬의 열을 구성하였지만, 하나의 단어 뿐만 아니라 2개의 단어(연속된 단어만 가능)로 이루어진 열 또한 만들어서 행렬을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "iw1Vm-neXtoG",
        "outputId": "b492dd06-e243-4e11-be4d-da3a87873719"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_e9208_row0_col0, #T_e9208_row0_col1 {\n",
              "  background-color: #fff7fb;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_e9208\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_e9208_level0_col0\" class=\"col_heading level0 col0\" >반갑습니다</th>\n",
              "      <th id=\"T_e9208_level0_col1\" class=\"col_heading level0 col1\" >안녕하세요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_e9208_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_e9208_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_e9208_row0_col1\" class=\"data row0 col1\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x12f264e50>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#N-grams를 적용하여 bow실습\n",
        "cvect = CountVectorizer(ngram_range= (1,1))\n",
        "X = cvect.fit_transform(corpus)\n",
        "dtm = X.toarray()\n",
        "pd.DataFrame(dtm, columns=cvect.get_feature_names_out()).style.background_gradient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvVvycO1bOQM"
      },
      "source": [
        "## 3-3 max_features\n",
        "* 기본값 = None\n",
        "* CountVectoriezr가 학습할 기능(어휘)의 양 제한\n",
        "* corpus중 빈도수가 가장 높은 순으로 해당 개수만큼만 추출\n",
        "* max_features = n 입력시 bow 행렬의 컬럼이 최대 n개까지만 생성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "dZCNplEGbVLC",
        "outputId": "7e62b617-8b14-4e01-dc24-6418ba6886a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>반갑습니다</th>\n",
              "      <th>안녕하세요</th>\n",
              "      <th>안녕하세요 반갑습니다</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   반갑습니다  안녕하세요  안녕하세요 반갑습니다\n",
              "0      1      1            1"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 10개의 단어로만 컬럼 형성하기\n",
        "cvect = CountVectorizer(ngram_range=(1, 2),max_features= 10 )\n",
        "X = cvect.fit_transform(corpus)\n",
        "dtm = X.toarray()\n",
        "\n",
        "# df_dtm.sum 으로 빈도수 합계 구하기\n",
        "pd.DataFrame(dtm, columns=cvect.get_feature_names_out())\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
